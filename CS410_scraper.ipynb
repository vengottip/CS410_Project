{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0ZuWZCey-Oo",
    "outputId": "a95a9610-f6f5-428e-d0c6-1dff05ec707c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ntscraper in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (0.3.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from ntscraper) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from ntscraper) (4.12.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from ntscraper) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from beautifulsoup4->ntscraper) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from requests->ntscraper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from requests->ntscraper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from requests->ntscraper) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from requests->ntscraper) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "pip install ntscraper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggWsc7j-S06D",
    "outputId": "c7bd5c3b-ace3-4b28-ea72-9cac49acbdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clean-text in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (0.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from clean-text) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from clean-text) (6.1.3)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\gvkri\\onedrive\\documents\\tech\\uiuc\\cs 410 text information systems\\projects\\team_project\\cs410_project\\cs410_venv\\lib\\site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.12)\n"
     ]
    }
   ],
   "source": [
    "pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lho4S1LPzYOY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-Dec-23 22:39:19 - Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter\n",
    "from cleantext import clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zx47h-6Szhj-",
    "outputId": "da1bad10-186c-4f91-9c59-a9f8d369e7bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|| 30/30 [01:02<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "scraper = Nitter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9te7aTQfBuOo"
   },
   "outputs": [],
   "source": [
    "def get_tweets(name,modes,num):\n",
    "    tweets = scraper.get_tweets(name,mode = modes,number=num, language = \"en\", filters = [\"nativeretweets\"])\n",
    "    final_tweets = []\n",
    "    for tweet in tweets['tweets']:\n",
    "        data = [tweet['link'], tweet['text'],tweet['date'],tweet['stats']['likes'],tweet['stats']['quotes'],tweet['stats']['comments'],tweet['stats']['retweets']]\n",
    "        final_tweets.append(data)\n",
    "    data = pd.DataFrame(final_tweets,columns= ['link','text','date','likes','quotes','comments','retweets'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27EmCwawN94w"
   },
   "source": [
    "APPL,MSFT,AMZN,NVDA,GOOGL,META,TSLA,\n",
    "Compare AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5c2RoRDAUgE",
    "outputId": "eeaadbb5-b435-4083-ed33-8d5f79f6a68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-Dec-23 22:42:17 - No instance specified, using random instance https://nitter.oksocial.net\n",
      "04-Dec-23 22:42:35 - Current stats for META: 3 tweets, 0 threads...\n",
      "04-Dec-23 22:42:40 - Current stats for META: 4 tweets, 0 threads...\n",
      "04-Dec-23 22:42:45 - Current stats for META: 4 tweets, 0 threads...\n",
      "                                                              link  \\\n",
      "0       https://twitter.com/plutsmeta/status/1726674776276767120#m   \n",
      "1    https://twitter.com/gapascarella/status/1731875907512492538#m   \n",
      "2  https://twitter.com/aliencybercoat/status/1731876568174047581#m   \n",
      "3      https://twitter.com/ImmersedVR/status/1712147704707498488#m   \n",
      "\n",
      "                                                                                                                                                                                                                                              text  \\\n",
      "0                                                                                                   Our whitepaper is ready, you can get acquainted with the Pluto universe.  https://pluts.io/WHITEPAPER.pdf #Pluto #P2EGame #meta #NFTCollection   \n",
      "1                            Facing the Firing Squad in @NHL @SenseArena  on Quest 3  #Meta #Quest3 #Gaming #Hockey #Training #Workout #VR #VirtualReality #Goalie #Goaltender #OnIce @penguins #Crosby #Malking #Guentzel #Letang #Fleury #Jarry   \n",
      "2  Rocky II - Gonna Fly Now 17 piece drum set included. Practice drums in VR with our drum simulator.  #vr #rocky #RockyBalboa #oculus #meta #metaquest #vrgames #boxing #pcgaming #musician #drums #steamvr #drumcover #xr #simulator #simulation   \n",
      "3                                                                                                                                                                                           Unboxing the Quest 3 for work. #meta #quest3 #workinvr   \n",
      "\n",
      "                         date  likes  quotes  comments  retweets  \n",
      "0  Nov 20, 2023 路 6:52 PM UTC    758      13        64       618  \n",
      "1   Dec 5, 2023 路 3:19 AM UTC      2       0         1         1  \n",
      "2   Dec 5, 2023 路 3:22 AM UTC      1       0         0         1  \n",
      "3  Oct 11, 2023 路 4:46 PM UTC    295      12        27        47  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "data = get_tweets('META','hashtag',20)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TF7IwTWNQ_BV"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.replace(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "data['text'] = data['text'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jn_s5Lz4rTt1",
    "outputId": "80380b88-bf0f-411d-996b-db925add7a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-Dec-23 22:45:46 - No instance specified, using random instance https://nitter.no-logs.com\n",
      "04-Dec-23 22:45:52 - Current stats for META: 1 tweets, 0 threads...\n",
      "04-Dec-23 22:45:57 - Current stats for META: 3 tweets, 0 threads...\n",
      "04-Dec-23 22:46:01 - Current stats for META: 4 tweets, 0 threads...\n",
      "04-Dec-23 22:46:05 - Current stats for META: 4 tweets, 0 threads...\n",
      "04-Dec-23 22:46:09 - No instance specified, using random instance https://nitter.d420.de\n",
      "04-Dec-23 22:46:16 - Current stats for MSFT: 10 tweets, 0 threads...\n",
      "04-Dec-23 22:46:16 - No instance specified, using random instance https://n.biendeo.com\n",
      "04-Dec-23 22:46:27 - Current stats for NVDA: 4 tweets, 0 threads...\n",
      "04-Dec-23 22:46:35 - Current stats for NVDA: 8 tweets, 0 threads...\n",
      "04-Dec-23 22:46:42 - Current stats for NVDA: 10 tweets, 0 threads...\n",
      "04-Dec-23 22:46:42 - No instance specified, using random instance https://nitter.perennialte.ch\n",
      "04-Dec-23 22:46:51 - Current stats for AMZN: 5 tweets, 0 threads...\n",
      "04-Dec-23 22:46:56 - Current stats for AMZN: 7 tweets, 0 threads...\n",
      "04-Dec-23 22:47:02 - Current stats for AMZN: 10 tweets, 0 threads...\n",
      "04-Dec-23 22:47:02 - No instance specified, using random instance https://nitter.adminforge.de\n",
      "04-Dec-23 22:47:09 - Current stats for TSLA: 10 tweets, 0 threads...\n",
      "04-Dec-23 22:47:09 - No instance specified, using random instance https://nitter.oksocial.net\n",
      "04-Dec-23 22:47:23 - Current stats for IBM: 7 tweets, 0 threads...\n",
      "04-Dec-23 22:47:31 - Current stats for IBM: 10 tweets, 0 threads...\n"
     ]
    }
   ],
   "source": [
    "    hashtag = ['META','MSFT',\"NVDA\",\"AMZN\",\"TSLA\",\"IBM\"]\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for i in hashtag:\n",
    "        update_data = get_tweets(i,'hashtag',10)\n",
    "        data = pd.concat([data, update_data], ignore_index=True)\n",
    "\n",
    "    data['text'] = data['text'].str.replace(\n",
    "        r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', regex=True)\n",
    "    data.to_csv('tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
